{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahsadadkhah/algorithms/blob/master/Copy_of_test_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ShgP6fajSRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3843c536-59cb-42e1-c6bc-2877f8f868b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hazm in /usr/local/lib/python3.10/dist-packages (0.9.3)\n",
            "Requirement already satisfied: fasttext-wheel<0.10.0,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (0.9.2)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (4.3.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.25.2)\n",
            "Requirement already satisfied: python-crfsuite<0.10.0,>=0.9.9 in /usr/local/lib/python3.10/dist-packages (from hazm) (0.9.9)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.2.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (2.11.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (6.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.65.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install hazm\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hazm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0CW-ZTUJzZE",
        "outputId": "0e4fb0c0-88b8-4cd2-e49d-0f2c9ee6a85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hazm in /usr/local/lib/python3.10/dist-packages (0.9.3)\n",
            "Requirement already satisfied: fasttext-wheel<0.10.0,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (0.9.2)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (4.3.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.25.2)\n",
            "Requirement already satisfied: python-crfsuite<0.10.0,>=0.9.9 in /usr/local/lib/python3.10/dist-packages (from hazm) (0.9.9)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.2.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (2.11.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (6.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.65.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f15L0VesN0-9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from hazm import *\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0N9OA4dm-wT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f7bbbd-d358-4bdf-c444-5315d1069c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/archive_5_085351.zip\n",
            "replace Snappfood - Sentiment Analysis.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# در اینجا فایل زیپ رو قرار بده و آنزیپش کن\n",
        "!unzip /content/archive_5_085351.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQcxo6ciO5uG",
        "outputId": "d25cac6a-28eb-4c3b-88bb-cef94c2f062a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-556b4e85f24c>:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df= pd.read_csv('/content/Snappfood - Sentiment Analysis.csv', sep='\\t' ,encoding='utf-8', error_bad_lines=False )\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'comment', 'label', 'label_id'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Read Data\n",
        "df= pd.read_csv('/content/Snappfood - Sentiment Analysis.csv', sep='\\t' ,encoding='utf-8', error_bad_lines=False )\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhCp1ME1nudp"
      },
      "outputs": [],
      "source": [
        "# حذف یک ستون اضافی\n",
        "df.drop('Unnamed: 0' , axis= 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fbP3n-fPe4cg",
        "outputId": "7f4bd897-1de3-4d07-acc4-672c725e95b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                comment  label  label_id\n",
              "0       واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح    SAD       1.0\n",
              "1     قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...  HAPPY       0.0\n",
              "2     قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...    SAD       1.0\n",
              "3     عالی بود همه چه درست و به اندازه و کیفیت خوب، ...  HAPPY       0.0\n",
              "4                         شیرینی وانیلی فقط یک مدل بود.  HAPPY       0.0\n",
              "...                                                 ...    ...       ...\n",
              "4995                         این پیتزا اصلا خوشمزه نبود    SAD       1.0\n",
              "4996  تعداد اسلایسایی که فرستاده شد از تعدادی که تو ...  HAPPY       0.0\n",
              "4997  برای ما قرار بود دونات شکلاتی بیارن ولی نداشتن...  HAPPY       0.0\n",
              "4998  در عکس آب‌گوشت و مخلفات داشت که نبود ولی کیفیت...  HAPPY       0.0\n",
              "4999  از نظر کیفیت عالی بود اما بسته بندی یکم جا برا...  HAPPY       0.0\n",
              "\n",
              "[4967 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-59d24da0-79fc-41ed-9731-bd8d5eddf3a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "      <th>label_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n",
              "      <td>SAD</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...</td>\n",
              "      <td>HAPPY</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...</td>\n",
              "      <td>SAD</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>عالی بود همه چه درست و به اندازه و کیفیت خوب، ...</td>\n",
              "      <td>HAPPY</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>شیرینی وانیلی فقط یک مدل بود.</td>\n",
              "      <td>HAPPY</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>این پیتزا اصلا خوشمزه نبود</td>\n",
              "      <td>SAD</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>تعداد اسلایسایی که فرستاده شد از تعدادی که تو ...</td>\n",
              "      <td>HAPPY</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>برای ما قرار بود دونات شکلاتی بیارن ولی نداشتن...</td>\n",
              "      <td>HAPPY</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>در عکس آب‌گوشت و مخلفات داشت که نبود ولی کیفیت...</td>\n",
              "      <td>HAPPY</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>از نظر کیفیت عالی بود اما بسته بندی یکم جا برا...</td>\n",
              "      <td>HAPPY</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4967 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59d24da0-79fc-41ed-9731-bd8d5eddf3a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-8efdac8e-4bb7-42c8-a917-4c53d96172d9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8efdac8e-4bb7-42c8-a917-4c53d96172d9')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-8efdac8e-4bb7-42c8-a917-4c53d96172d9 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59d24da0-79fc-41ed-9731-bd8d5eddf3a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59d24da0-79fc-41ed-9731-bd8d5eddf3a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO7WItEDoEhl"
      },
      "outputs": [],
      "source": [
        "df = df. head(5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yOwinAEoch6"
      },
      "outputs": [],
      "source": [
        "# حذف سطر های خالی\n",
        "df.label_id.unique()\n",
        "df= df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaSs5ZM8Uv9H",
        "outputId": "aa386ca3-726a-4d80-88fb-b348e24201c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# دوتا مقدار داره و مقدار خالی پاک شده\n",
        "df.label_id.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGrAdurGo7Fj"
      },
      "outputs": [],
      "source": [
        "# نورمالیز داده ها برای اینکه برای شبکه قابل فهم تر باشه\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "normalizer = Normalizer()\n",
        "df['comment'] = df['comment'].apply(normalizer.normalize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw_bExzAoIfC"
      },
      "outputs": [],
      "source": [
        "# تقسیم داده ها به دو ببخش تست و ترین\n",
        "\n",
        "y= df.label_id.values.astype(int)\n",
        "x= df.comment.values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state= 21)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgOAgXFyK8Z6",
        "outputId": "910c980b-c2e8-47c2-f283-55969ac6c27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpkG0dlTRgtl"
      },
      "outputs": [],
      "source": [
        "# استفاده از این کلاس برای خواندن داده ها به شکلی که برای شبکه مناسب باشه\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Tokenization and encoding\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.texts[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        encoding = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=512,  # Adjust as needed\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'label': torch.tensor(label)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_3DN5S4QE5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4917cbfd-325e-4cc3-bf04-af7803a3438c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# حداکثر بچ سایز 16 می باشد\n",
        "\n",
        "# Prepare training data\n",
        "dataset = TextDataset(x_train, y_train)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Prepare testing data\n",
        "dataset2 = TextDataset(x_test, y_test)\n",
        "dataloader_test = DataLoader(dataset2, batch_size=16)\n",
        "\n",
        "# Load pre-trained BERT model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
        "\n",
        "# Training loop\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sTRTrQIQ_s_"
      },
      "outputs": [],
      "source": [
        "# اگر خواستی تست کنی که یک بج ( شامل یک مقدار 32 تایی) رو درست خونده\n",
        "\n",
        "# batch=next(iter(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxwgeic1RC0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7546b76-c382-43f7-db05-ce3e449d633c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Batch : 0 loss = 0.6804710030555725\n",
            "0\n",
            "Batch : 1 loss = 0.6844934225082397\n",
            "1\n",
            "Batch : 2 loss = 0.6685056090354919\n",
            "1\n",
            "Batch : 3 loss = 0.7397177815437317\n",
            "1\n",
            "Batch : 4 loss = 0.6926943063735962\n",
            "1\n",
            "Batch : 5 loss = 0.7287580370903015\n",
            "0\n",
            "Batch : 6 loss = 0.6976159811019897\n",
            "0\n",
            "Batch : 7 loss = 0.6792181730270386\n",
            "0\n",
            "Batch : 8 loss = 0.7218736410140991\n",
            "0\n",
            "Batch : 9 loss = 0.6925139427185059\n",
            "0\n",
            "Batch : 10 loss = 0.711522102355957\n",
            "0\n",
            "Batch : 11 loss = 0.6982159614562988\n",
            "0\n",
            "Batch : 12 loss = 0.714117169380188\n",
            "0\n",
            "Batch : 13 loss = 0.7158710956573486\n",
            "0\n",
            "Batch : 14 loss = 0.7159267067909241\n",
            "0\n",
            "Batch : 15 loss = 0.6903365850448608\n",
            "0\n",
            "Batch : 16 loss = 0.6814595460891724\n",
            "0\n",
            "Batch : 17 loss = 0.7030133605003357\n",
            "0\n",
            "Batch : 18 loss = 0.6633245348930359\n",
            "0\n",
            "Batch : 19 loss = 0.7013387680053711\n",
            "0\n",
            "Batch : 20 loss = 0.6897647380828857\n",
            "1\n",
            "Batch : 21 loss = 0.6590297222137451\n",
            "0\n",
            "Batch : 22 loss = 0.6623992323875427\n",
            "1\n",
            "Batch : 23 loss = 0.683091938495636\n",
            "0\n",
            "Batch : 24 loss = 0.6785293817520142\n",
            "1\n",
            "Batch : 25 loss = 0.6871498823165894\n",
            "1\n",
            "Batch : 26 loss = 0.6488426327705383\n",
            "1\n",
            "Batch : 27 loss = 0.6883779168128967\n",
            "1\n",
            "Batch : 28 loss = 0.6201799511909485\n",
            "1\n",
            "Batch : 29 loss = 0.6790943741798401\n",
            "1\n",
            "Batch : 30 loss = 0.6405577659606934\n",
            "1\n",
            "Batch : 31 loss = 0.5777063369750977\n",
            "1\n",
            "Batch : 32 loss = 0.6195525527000427\n",
            "1\n",
            "Batch : 33 loss = 0.6765289902687073\n",
            "1\n",
            "Batch : 34 loss = 0.5252307653427124\n",
            "1\n",
            "Batch : 35 loss = 0.5856508612632751\n",
            "1\n",
            "Batch : 36 loss = 0.3650588393211365\n",
            "1\n",
            "Batch : 37 loss = 0.3331005871295929\n",
            "1\n",
            "Batch : 38 loss = 0.7387745976448059\n",
            "1\n",
            "Batch : 39 loss = 0.786543071269989\n",
            "1\n",
            "Batch : 40 loss = 0.37906867265701294\n",
            "0\n",
            "Batch : 41 loss = 0.5876354575157166\n",
            "0\n",
            "Batch : 42 loss = 0.4715670645236969\n",
            "0\n",
            "Batch : 43 loss = 0.8384522199630737\n",
            "0\n",
            "Batch : 44 loss = 0.599431037902832\n",
            "0\n",
            "Batch : 45 loss = 0.6287539005279541\n",
            "0\n",
            "Batch : 46 loss = 0.4373600482940674\n",
            "1\n",
            "Batch : 47 loss = 0.396428644657135\n",
            "1\n",
            "Batch : 48 loss = 0.5838736891746521\n",
            "1\n",
            "Batch : 49 loss = 0.6579458713531494\n",
            "1\n",
            "Batch : 50 loss = 0.5885597467422485\n",
            "0\n",
            "Batch : 51 loss = 0.652499794960022\n",
            "1\n",
            "Batch : 52 loss = 0.5099203586578369\n",
            "0\n",
            "Batch : 53 loss = 0.4836372137069702\n",
            "0\n",
            "Batch : 54 loss = 0.6554862260818481\n",
            "1\n",
            "Batch : 55 loss = 0.49183690547943115\n",
            "1\n",
            "Batch : 56 loss = 0.5046356320381165\n",
            "1\n",
            "Batch : 57 loss = 0.5051414966583252\n",
            "0\n",
            "Batch : 58 loss = 0.4632798135280609\n",
            "1\n",
            "Batch : 59 loss = 0.34450772404670715\n",
            "1\n",
            "Batch : 60 loss = 0.6695180535316467\n",
            "0\n",
            "Batch : 61 loss = 0.5672345161437988\n",
            "1\n",
            "Batch : 62 loss = 0.58660888671875\n",
            "0\n",
            "Batch : 63 loss = 0.306245893239975\n",
            "1\n",
            "Batch : 64 loss = 0.30589452385902405\n",
            "1\n",
            "Batch : 65 loss = 0.4452148973941803\n",
            "0\n",
            "Batch : 66 loss = 0.8433659076690674\n",
            "0\n",
            "Batch : 67 loss = 0.523328423500061\n",
            "0\n",
            "Batch : 68 loss = 0.6834467053413391\n",
            "0\n",
            "Batch : 69 loss = 0.37139052152633667\n",
            "0\n",
            "Batch : 70 loss = 0.28700903058052063\n",
            "1\n",
            "Batch : 71 loss = 0.4584224820137024\n",
            "0\n",
            "Batch : 72 loss = 0.5528353452682495\n",
            "1\n",
            "Batch : 73 loss = 0.5854801535606384\n",
            "1\n",
            "Batch : 74 loss = 0.6529164910316467\n",
            "1\n",
            "Batch : 75 loss = 0.41781583428382874\n",
            "1\n",
            "Batch : 76 loss = 0.7088285088539124\n",
            "0\n",
            "Batch : 77 loss = 0.5324481725692749\n",
            "0\n",
            "Batch : 78 loss = 0.3954152464866638\n",
            "1\n",
            "Batch : 79 loss = 0.7585623264312744\n",
            "0\n",
            "Batch : 80 loss = 0.30056896805763245\n",
            "1\n",
            "Batch : 81 loss = 0.5955781936645508\n",
            "1\n",
            "Batch : 82 loss = 0.44129690527915955\n",
            "1\n",
            "Batch : 83 loss = 0.4258970022201538\n",
            "0\n",
            "Batch : 84 loss = 0.31295591592788696\n",
            "1\n",
            "Batch : 85 loss = 0.2962743043899536\n",
            "0\n",
            "Batch : 86 loss = 0.5474002957344055\n",
            "1\n",
            "Batch : 87 loss = 0.6452948451042175\n",
            "1\n",
            "Batch : 88 loss = 0.6352365612983704\n",
            "1\n",
            "Batch : 89 loss = 0.7342681884765625\n",
            "1\n",
            "Batch : 90 loss = 0.15677441656589508\n",
            "0\n",
            "Batch : 91 loss = 0.5444107055664062\n",
            "1\n",
            "Batch : 92 loss = 0.48345768451690674\n",
            "1\n",
            "Batch : 93 loss = 0.5448123812675476\n",
            "1\n",
            "Batch : 94 loss = 0.42124104499816895\n",
            "1\n",
            "Batch : 95 loss = 0.49936437606811523\n",
            "1\n",
            "Batch : 96 loss = 0.49459701776504517\n",
            "1\n",
            "Batch : 97 loss = 0.39791226387023926\n",
            "1\n",
            "Batch : 98 loss = 0.4434545636177063\n",
            "0\n",
            "Batch : 99 loss = 0.47132939100265503\n",
            "0\n",
            "Batch : 100 loss = 0.4034886956214905\n",
            "0\n",
            "Batch : 101 loss = 0.533237099647522\n",
            "1\n",
            "Batch : 102 loss = 0.48251888155937195\n",
            "1\n",
            "Batch : 103 loss = 0.27834901213645935\n",
            "0\n",
            "Batch : 104 loss = 0.45701760053634644\n",
            "0\n",
            "Batch : 105 loss = 0.1942705661058426\n",
            "0\n",
            "Batch : 106 loss = 0.4839684069156647\n",
            "0\n",
            "Batch : 107 loss = 0.5976346731185913\n",
            "1\n",
            "Batch : 108 loss = 0.27202707529067993\n",
            "1\n",
            "Batch : 109 loss = 0.5317610502243042\n",
            "1\n",
            "Batch : 110 loss = 0.45447468757629395\n",
            "0\n",
            "Batch : 111 loss = 0.3728824257850647\n",
            "1\n",
            "Batch : 112 loss = 0.4265621602535248\n",
            "1\n",
            "Batch : 113 loss = 0.3301103711128235\n",
            "1\n",
            "Batch : 114 loss = 0.5139347910881042\n",
            "1\n",
            "Batch : 115 loss = 0.33541029691696167\n",
            "1\n",
            "Batch : 116 loss = 0.3116527795791626\n",
            "0\n",
            "Batch : 117 loss = 0.27183037996292114\n",
            "1\n",
            "Batch : 118 loss = 0.4741145074367523\n",
            "1\n",
            "Batch : 119 loss = 0.42800235748291016\n",
            "1\n",
            "Batch : 120 loss = 0.21120713651180267\n",
            "1\n",
            "Batch : 121 loss = 0.4864610433578491\n",
            "1\n",
            "Batch : 122 loss = 0.47052615880966187\n",
            "0\n",
            "Batch : 123 loss = 0.48774275183677673\n",
            "1\n",
            "Batch : 124 loss = 0.5777097940444946\n",
            "1\n",
            "Batch : 125 loss = 0.6999091506004333\n",
            "0\n",
            "Batch : 126 loss = 0.17738448083400726\n",
            "1\n",
            "Batch : 127 loss = 0.7550327181816101\n",
            "1\n",
            "Batch : 128 loss = 0.750421941280365\n",
            "1\n",
            "Batch : 129 loss = 0.1635742485523224\n",
            "1\n",
            "Batch : 130 loss = 0.2302515059709549\n",
            "1\n",
            "Batch : 131 loss = 0.5723232626914978\n",
            "1\n",
            "Batch : 132 loss = 0.23645532131195068\n",
            "1\n",
            "Batch : 133 loss = 0.2586616575717926\n",
            "1\n",
            "Batch : 134 loss = 0.3169765770435333\n",
            "0\n",
            "Batch : 135 loss = 0.43010687828063965\n",
            "1\n",
            "Batch : 136 loss = 0.3624759018421173\n",
            "1\n",
            "Batch : 137 loss = 0.29602617025375366\n",
            "1\n",
            "Batch : 138 loss = 0.5142855048179626\n",
            "1\n",
            "Batch : 139 loss = 0.29136815667152405\n",
            "0\n",
            "Batch : 140 loss = 0.6569799780845642\n",
            "0\n",
            "Batch : 141 loss = 0.5268963575363159\n",
            "1\n",
            "Batch : 142 loss = 0.5121669173240662\n",
            "1\n",
            "Batch : 143 loss = 0.3120306134223938\n",
            "0\n",
            "Batch : 144 loss = 0.22033211588859558\n",
            "1\n",
            "Batch : 145 loss = 0.5313132405281067\n",
            "0\n",
            "Batch : 146 loss = 0.719872236251831\n",
            "1\n",
            "Batch : 147 loss = 0.27577775716781616\n",
            "1\n",
            "Batch : 148 loss = 0.5979889035224915\n",
            "0\n",
            "Batch : 149 loss = 0.6054883599281311\n",
            "0\n",
            "Batch : 150 loss = 0.48664557933807373\n",
            "0\n",
            "Batch : 151 loss = 0.38279685378074646\n",
            "1\n",
            "Batch : 152 loss = 0.5749115943908691\n",
            "0\n",
            "Batch : 153 loss = 0.4945865273475647\n",
            "1\n",
            "Batch : 154 loss = 0.35726162791252136\n",
            "0\n",
            "Batch : 155 loss = 0.34390518069267273\n",
            "1\n",
            "Batch : 156 loss = 0.4195365607738495\n",
            "0\n",
            "Batch : 157 loss = 0.3367908298969269\n",
            "1\n",
            "Batch : 158 loss = 0.4628963768482208\n",
            "0\n",
            "Batch : 159 loss = 0.4013601541519165\n",
            "0\n",
            "Batch : 160 loss = 0.3276372253894806\n",
            "0\n",
            "Batch : 161 loss = 0.4522370994091034\n",
            "0\n",
            "Batch : 162 loss = 0.23277872800827026\n",
            "1\n",
            "Batch : 163 loss = 0.4311671257019043\n",
            "1\n",
            "Batch : 164 loss = 0.3154771029949188\n",
            "0\n",
            "Batch : 165 loss = 0.37277525663375854\n",
            "0\n",
            "Batch : 166 loss = 0.3789284825325012\n",
            "0\n",
            "Batch : 167 loss = 0.6579421758651733\n",
            "1\n",
            "Batch : 168 loss = 0.630050003528595\n",
            "0\n",
            "Batch : 169 loss = 0.46204280853271484\n",
            "0\n",
            "Batch : 170 loss = 0.215728759765625\n",
            "0\n",
            "Batch : 171 loss = 0.5738059878349304\n",
            "1\n",
            "Batch : 172 loss = 0.23228894174098969\n",
            "1\n",
            "Batch : 173 loss = 0.24482186138629913\n",
            "0\n",
            "Batch : 174 loss = 0.5056936740875244\n",
            "0\n",
            "Batch : 175 loss = 0.54476398229599\n",
            "0\n",
            "Batch : 176 loss = 0.9704962968826294\n",
            "1\n",
            "Batch : 177 loss = 0.5179967880249023\n",
            "1\n",
            "Batch : 178 loss = 0.8081380128860474\n",
            "0\n",
            "Batch : 179 loss = 0.5704404711723328\n",
            "0\n",
            "Batch : 180 loss = 0.5325583219528198\n",
            "1\n",
            "Batch : 181 loss = 0.30240491032600403\n",
            "1\n",
            "Batch : 182 loss = 0.47845229506492615\n",
            "0\n",
            "Batch : 183 loss = 0.37890076637268066\n",
            "1\n",
            "Batch : 184 loss = 0.43932822346687317\n",
            "0\n",
            "Batch : 185 loss = 0.26358702778816223\n",
            "0\n",
            "Batch : 186 loss = 0.300322949886322\n",
            "0\n",
            "Batch : 187 loss = 0.4261432886123657\n",
            "1\n",
            "Batch : 188 loss = 0.3963579535484314\n",
            "0\n",
            "Batch : 189 loss = 0.3795415759086609\n",
            "0\n",
            "Batch : 190 loss = 0.3054218590259552\n",
            "1\n",
            "Batch : 191 loss = 0.33159139752388\n",
            "0\n",
            "Batch : 192 loss = 0.33529409766197205\n",
            "1\n",
            "Batch : 193 loss = 0.29809024930000305\n",
            "1\n",
            "Batch : 194 loss = 0.2828439176082611\n",
            "0\n",
            "Batch : 195 loss = 0.3647032082080841\n",
            "0\n",
            "Batch : 196 loss = 0.3643932342529297\n",
            "0\n",
            "Batch : 197 loss = 0.30418041348457336\n",
            "1\n",
            "Batch : 198 loss = 0.4785396456718445\n",
            "1\n",
            "Batch : 199 loss = 0.6581103801727295\n",
            "1\n",
            "Batch : 200 loss = 0.5927313566207886\n",
            "0\n",
            "Batch : 201 loss = 0.18047063052654266\n",
            "1\n",
            "Batch : 202 loss = 0.5275001525878906\n",
            "0\n",
            "Batch : 203 loss = 0.11419743299484253\n",
            "1\n",
            "Batch : 204 loss = 0.39297181367874146\n",
            "1\n",
            "Batch : 205 loss = 0.3650108873844147\n",
            "0\n",
            "Batch : 206 loss = 0.2335551530122757\n",
            "0\n",
            "Batch : 207 loss = 0.43100303411483765\n",
            "0\n",
            "Batch : 208 loss = 0.28585803508758545\n",
            "0\n",
            "Batch : 209 loss = 0.08973643183708191\n",
            "1\n",
            "Batch : 210 loss = 0.46144625544548035\n",
            "1\n",
            "Batch : 211 loss = 0.2915113866329193\n",
            "1\n",
            "Batch : 212 loss = 0.48139840364456177\n",
            "0\n",
            "Batch : 213 loss = 0.3989473879337311\n",
            "1\n",
            "Batch : 214 loss = 0.3358222246170044\n",
            "0\n",
            "Batch : 215 loss = 0.2511492669582367\n",
            "1\n",
            "Batch : 216 loss = 0.6546487808227539\n",
            "1\n",
            "Batch : 217 loss = 0.33275076746940613\n",
            "0\n",
            "Batch : 218 loss = 0.1751282662153244\n",
            "1\n",
            "Batch : 219 loss = 0.47577065229415894\n",
            "0\n",
            "Batch : 220 loss = 0.4326270520687103\n",
            "0\n",
            "Batch : 221 loss = 0.5822253227233887\n",
            "1\n",
            "Batch : 222 loss = 0.5465232729911804\n",
            "0\n",
            "Batch : 223 loss = 0.5636815428733826\n",
            "1\n",
            "Batch : 224 loss = 0.6259422302246094\n",
            "1\n",
            "Batch : 225 loss = 0.3564062714576721\n",
            "0\n",
            "Batch : 226 loss = 0.22208771109580994\n",
            "1\n",
            "Batch : 227 loss = 0.4083924889564514\n",
            "1\n",
            "Batch : 228 loss = 0.568166971206665\n",
            "1\n",
            "Batch : 229 loss = 0.42800360918045044\n",
            "0\n",
            "Batch : 230 loss = 0.41742733120918274\n",
            "0\n",
            "Batch : 231 loss = 0.41877055168151855\n",
            "1\n",
            "Batch : 232 loss = 0.35887426137924194\n",
            "0\n",
            "Batch : 233 loss = 0.4828684329986572\n",
            "1\n",
            "Batch : 234 loss = 0.22908173501491547\n",
            "1\n",
            "Batch : 235 loss = 0.44480833411216736\n",
            "1\n",
            "Batch : 236 loss = 0.3497559726238251\n",
            "1\n",
            "Batch : 237 loss = 0.1614409238100052\n",
            "0\n",
            "Batch : 238 loss = 0.37003234028816223\n",
            "1\n",
            "Batch : 239 loss = 0.28118839859962463\n",
            "1\n",
            "Batch : 240 loss = 0.8183119297027588\n",
            "0\n",
            "Batch : 241 loss = 0.4014527499675751\n",
            "1\n",
            "Batch : 242 loss = 0.21466778218746185\n",
            "0\n",
            "Batch : 243 loss = 0.5589755773544312\n",
            "1\n",
            "Batch : 244 loss = 0.6536529064178467\n",
            "0\n",
            "Batch : 245 loss = 0.4945598840713501\n",
            "1\n",
            "Batch : 246 loss = 0.539247989654541\n",
            "0\n",
            "Batch : 247 loss = 0.5207528471946716\n",
            "0\n",
            "Batch : 248 loss = 0.5339099764823914\n",
            "0\n",
            "Batch : 249 loss = 0.3689757287502289\n",
            "0\n",
            "Batch : 250 loss = 0.3999313712120056\n",
            "1\n",
            "Batch : 251 loss = 0.6859869956970215\n",
            "1\n",
            "Batch : 252 loss = 0.46388328075408936\n",
            "1\n",
            "Batch : 253 loss = 0.47959432005882263\n",
            "1\n",
            "Batch : 254 loss = 0.2578181028366089\n",
            "1\n",
            "Batch : 255 loss = 0.27546414732933044\n",
            "1\n",
            "Batch : 256 loss = 0.2701745629310608\n",
            "1\n",
            "Batch : 257 loss = 0.28850987553596497\n",
            "1\n",
            "Batch : 258 loss = 0.4922372102737427\n",
            "1\n",
            "Batch : 259 loss = 0.360627144575119\n",
            "1\n",
            "Batch : 260 loss = 0.759810745716095\n",
            "0\n",
            "Batch : 261 loss = 0.5889363288879395\n",
            "1\n",
            "Batch : 262 loss = 0.6335456967353821\n",
            "0\n",
            "Batch : 263 loss = 0.3140522241592407\n",
            "1\n",
            "Batch : 0 loss = 0.33424150943756104\n",
            "1\n",
            "Batch : 1 loss = 0.24276645481586456\n",
            "0\n",
            "Batch : 2 loss = 0.430222749710083\n",
            "0\n",
            "Batch : 3 loss = 0.43231135606765747\n",
            "1\n",
            "Batch : 4 loss = 0.39607757329940796\n",
            "1\n",
            "Batch : 5 loss = 0.32476773858070374\n",
            "1\n",
            "Batch : 6 loss = 0.27982455492019653\n",
            "1\n",
            "Batch : 7 loss = 0.3078775107860565\n",
            "0\n",
            "Batch : 8 loss = 0.19427432119846344\n",
            "0\n",
            "Batch : 9 loss = 0.28920069336891174\n",
            "0\n",
            "Batch : 10 loss = 0.7610622048377991\n",
            "1\n",
            "Batch : 11 loss = 0.3481186032295227\n",
            "0\n",
            "Batch : 12 loss = 0.42175206542015076\n",
            "0\n",
            "Batch : 13 loss = 0.29898813366889954\n",
            "1\n",
            "Batch : 14 loss = 0.36601507663726807\n",
            "1\n",
            "Batch : 15 loss = 0.36344510316848755\n",
            "0\n",
            "Batch : 16 loss = 0.2508113980293274\n",
            "1\n",
            "Batch : 17 loss = 0.5265015959739685\n",
            "1\n",
            "Batch : 18 loss = 0.5491804480552673\n",
            "1\n",
            "Batch : 19 loss = 0.6744316816329956\n",
            "1\n",
            "Batch : 20 loss = 0.24248461425304413\n",
            "1\n",
            "Batch : 21 loss = 0.2697973847389221\n",
            "0\n",
            "Batch : 22 loss = 0.4735926687717438\n",
            "0\n",
            "Batch : 23 loss = 0.15581318736076355\n",
            "1\n",
            "Batch : 24 loss = 0.16404789686203003\n",
            "1\n",
            "Batch : 25 loss = 0.41465771198272705\n",
            "0\n",
            "Batch : 26 loss = 0.29490432143211365\n",
            "1\n",
            "Batch : 27 loss = 0.21567818522453308\n",
            "0\n",
            "Batch : 28 loss = 0.6098824739456177\n",
            "1\n",
            "Batch : 29 loss = 0.4579969048500061\n",
            "0\n",
            "Batch : 30 loss = 0.12872204184532166\n",
            "0\n",
            "Batch : 31 loss = 0.591760516166687\n",
            "1\n",
            "Batch : 32 loss = 0.30484750866889954\n",
            "1\n",
            "Batch : 33 loss = 0.22730031609535217\n",
            "0\n",
            "Batch : 34 loss = 0.36968204379081726\n",
            "1\n",
            "Batch : 35 loss = 0.4476042091846466\n",
            "1\n",
            "Batch : 36 loss = 0.37835338711738586\n",
            "0\n",
            "Batch : 37 loss = 0.25182169675827026\n",
            "0\n",
            "Batch : 38 loss = 0.35032376646995544\n",
            "0\n",
            "Batch : 39 loss = 0.12889987230300903\n",
            "1\n",
            "Batch : 40 loss = 0.23145529627799988\n",
            "1\n",
            "Batch : 41 loss = 0.3555055558681488\n",
            "1\n",
            "Batch : 42 loss = 0.2730392813682556\n",
            "1\n",
            "Batch : 43 loss = 0.24643529951572418\n",
            "0\n",
            "Batch : 44 loss = 0.5740094184875488\n",
            "1\n",
            "Batch : 45 loss = 0.4872009754180908\n",
            "0\n",
            "Batch : 46 loss = 0.5028447508811951\n",
            "1\n",
            "Batch : 47 loss = 0.22547107934951782\n",
            "1\n",
            "Batch : 48 loss = 0.255174845457077\n",
            "0\n",
            "Batch : 49 loss = 0.21921388804912567\n",
            "0\n",
            "Batch : 50 loss = 0.26155850291252136\n",
            "0\n",
            "Batch : 51 loss = 0.504510223865509\n",
            "1\n",
            "Batch : 52 loss = 0.4973049461841583\n",
            "0\n",
            "Batch : 53 loss = 0.7171794772148132\n",
            "0\n",
            "Batch : 54 loss = 0.5295394659042358\n",
            "1\n",
            "Batch : 55 loss = 0.3448129892349243\n",
            "1\n",
            "Batch : 56 loss = 0.28955820202827454\n",
            "0\n",
            "Batch : 57 loss = 0.18616753816604614\n",
            "1\n",
            "Batch : 58 loss = 0.7450709939002991\n",
            "1\n",
            "Batch : 59 loss = 0.31247881054878235\n",
            "0\n",
            "Batch : 60 loss = 0.2617672383785248\n",
            "1\n",
            "Batch : 61 loss = 0.37108397483825684\n",
            "0\n",
            "Batch : 62 loss = 0.3190557658672333\n",
            "1\n",
            "Batch : 63 loss = 0.4881543219089508\n",
            "1\n",
            "Batch : 64 loss = 0.3844171166419983\n",
            "1\n",
            "Batch : 65 loss = 0.25181469321250916\n",
            "0\n",
            "Batch : 66 loss = 0.43419817090034485\n",
            "1\n",
            "Batch : 67 loss = 0.43982118368148804\n",
            "1\n",
            "Batch : 68 loss = 0.4371454119682312\n",
            "0\n",
            "Batch : 69 loss = 0.3635973632335663\n",
            "0\n",
            "Batch : 70 loss = 0.5080307126045227\n",
            "0\n",
            "Batch : 71 loss = 0.22706109285354614\n",
            "1\n",
            "Batch : 72 loss = 0.2545703053474426\n",
            "0\n",
            "Batch : 73 loss = 0.1246989294886589\n",
            "1\n",
            "Batch : 74 loss = 0.3790801763534546\n",
            "1\n",
            "Batch : 75 loss = 0.4205493927001953\n",
            "1\n",
            "Batch : 76 loss = 0.29047155380249023\n",
            "0\n",
            "Batch : 77 loss = 0.16219386458396912\n",
            "0\n",
            "Batch : 78 loss = 0.5282068848609924\n",
            "0\n",
            "Batch : 79 loss = 0.1840820014476776\n",
            "1\n",
            "Batch : 80 loss = 0.4789971709251404\n",
            "0\n",
            "Batch : 81 loss = 0.5614137649536133\n",
            "1\n",
            "Batch : 82 loss = 0.30758219957351685\n",
            "1\n",
            "Batch : 83 loss = 0.2335357666015625\n",
            "0\n",
            "Batch : 84 loss = 0.17809832096099854\n",
            "0\n",
            "Batch : 85 loss = 0.19524791836738586\n",
            "0\n",
            "Batch : 86 loss = 0.18770499527454376\n",
            "1\n",
            "Batch : 87 loss = 0.4480459690093994\n",
            "1\n",
            "Batch : 88 loss = 0.20289984345436096\n",
            "1\n",
            "Batch : 89 loss = 0.21619002521038055\n",
            "0\n",
            "Batch : 90 loss = 0.26231589913368225\n",
            "1\n",
            "Batch : 91 loss = 0.33686086535453796\n",
            "1\n",
            "Batch : 92 loss = 0.08279146254062653\n",
            "0\n",
            "Batch : 93 loss = 0.5034235119819641\n",
            "0\n",
            "Batch : 94 loss = 0.25686877965927124\n",
            "1\n",
            "Batch : 95 loss = 0.14695344865322113\n",
            "0\n",
            "Batch : 96 loss = 0.19966267049312592\n",
            "1\n",
            "Batch : 97 loss = 0.2751423120498657\n",
            "1\n",
            "Batch : 98 loss = 0.5837504863739014\n",
            "1\n",
            "Batch : 99 loss = 0.3286345303058624\n",
            "1\n",
            "Batch : 100 loss = 0.05589829385280609\n",
            "1\n",
            "Batch : 101 loss = 0.1496472805738449\n",
            "1\n",
            "Batch : 102 loss = 0.19294163584709167\n",
            "1\n",
            "Batch : 103 loss = 0.3630446195602417\n",
            "0\n",
            "Batch : 104 loss = 0.21238411962985992\n",
            "1\n",
            "Batch : 105 loss = 0.2547714412212372\n",
            "1\n",
            "Batch : 106 loss = 0.3176718056201935\n",
            "0\n",
            "Batch : 107 loss = 0.32399097084999084\n",
            "0\n",
            "Batch : 108 loss = 0.5392922163009644\n",
            "1\n",
            "Batch : 109 loss = 0.41344887018203735\n",
            "1\n",
            "Batch : 110 loss = 0.3603823781013489\n",
            "1\n",
            "Batch : 111 loss = 0.3657057285308838\n",
            "1\n",
            "Batch : 112 loss = 0.5378851890563965\n",
            "1\n",
            "Batch : 113 loss = 0.3119259178638458\n",
            "0\n",
            "Batch : 114 loss = 0.24533894658088684\n",
            "1\n",
            "Batch : 115 loss = 0.38798609375953674\n",
            "1\n",
            "Batch : 116 loss = 0.6123523712158203\n",
            "1\n",
            "Batch : 117 loss = 0.3692686855792999\n",
            "0\n",
            "Batch : 118 loss = 0.2505422830581665\n",
            "0\n",
            "Batch : 119 loss = 0.4222935736179352\n",
            "1\n",
            "Batch : 120 loss = 0.14537949860095978\n",
            "1\n",
            "Batch : 121 loss = 0.32496294379234314\n",
            "1\n",
            "Batch : 122 loss = 0.6091299057006836\n",
            "1\n",
            "Batch : 123 loss = 0.24979674816131592\n",
            "1\n",
            "Batch : 124 loss = 0.3399086892604828\n",
            "1\n",
            "Batch : 125 loss = 0.334739625453949\n",
            "1\n",
            "Batch : 126 loss = 0.36412280797958374\n",
            "0\n",
            "Batch : 127 loss = 0.2346956729888916\n",
            "1\n",
            "Batch : 128 loss = 0.3736042082309723\n",
            "0\n",
            "Batch : 129 loss = 0.17377594113349915\n",
            "1\n",
            "Batch : 130 loss = 0.2476087063550949\n",
            "1\n",
            "Batch : 131 loss = 0.19936245679855347\n",
            "0\n",
            "Batch : 132 loss = 0.23840005695819855\n",
            "0\n",
            "Batch : 133 loss = 0.36417585611343384\n",
            "1\n",
            "Batch : 134 loss = 0.4102131426334381\n",
            "1\n",
            "Batch : 135 loss = 0.39650237560272217\n",
            "0\n",
            "Batch : 136 loss = 0.39866089820861816\n",
            "0\n",
            "Batch : 137 loss = 0.46925079822540283\n",
            "0\n",
            "Batch : 138 loss = 0.21822483837604523\n",
            "0\n",
            "Batch : 139 loss = 0.43359869718551636\n",
            "1\n",
            "Batch : 140 loss = 0.37298011779785156\n",
            "1\n",
            "Batch : 141 loss = 0.18574446439743042\n",
            "1\n",
            "Batch : 142 loss = 0.3899882435798645\n",
            "1\n",
            "Batch : 143 loss = 0.19441109895706177\n",
            "0\n",
            "Batch : 144 loss = 0.21634750068187714\n",
            "1\n",
            "Batch : 145 loss = 0.4773924946784973\n",
            "0\n",
            "Batch : 146 loss = 0.16525498032569885\n",
            "0\n",
            "Batch : 147 loss = 0.5100533962249756\n",
            "1\n",
            "Batch : 148 loss = 0.26278260350227356\n",
            "1\n",
            "Batch : 149 loss = 0.5530489087104797\n",
            "0\n",
            "Batch : 150 loss = 0.4240603744983673\n",
            "1\n",
            "Batch : 151 loss = 0.4503266215324402\n",
            "1\n",
            "Batch : 152 loss = 0.456032395362854\n",
            "0\n",
            "Batch : 153 loss = 0.20466922223567963\n",
            "0\n",
            "Batch : 154 loss = 0.5632095336914062\n",
            "0\n",
            "Batch : 155 loss = 0.3156222403049469\n",
            "0\n",
            "Batch : 156 loss = 0.28093668818473816\n",
            "1\n",
            "Batch : 157 loss = 0.2159298211336136\n",
            "0\n",
            "Batch : 158 loss = 0.14878080785274506\n",
            "0\n",
            "Batch : 159 loss = 0.34986770153045654\n",
            "1\n",
            "Batch : 160 loss = 0.5723958611488342\n",
            "1\n",
            "Batch : 161 loss = 0.4243207275867462\n",
            "1\n",
            "Batch : 162 loss = 0.6753162741661072\n",
            "1\n",
            "Batch : 163 loss = 0.2800636291503906\n",
            "1\n",
            "Batch : 164 loss = 0.5984071493148804\n",
            "0\n",
            "Batch : 165 loss = 0.38072338700294495\n",
            "1\n",
            "Batch : 166 loss = 0.24394766986370087\n",
            "1\n",
            "Batch : 167 loss = 0.41642364859580994\n",
            "1\n",
            "Batch : 168 loss = 0.4035220146179199\n",
            "0\n",
            "Batch : 169 loss = 0.3096204102039337\n",
            "1\n",
            "Batch : 170 loss = 0.27635788917541504\n",
            "1\n",
            "Batch : 171 loss = 0.22240035235881805\n",
            "0\n",
            "Batch : 172 loss = 0.48570165038108826\n",
            "0\n",
            "Batch : 173 loss = 0.4536638855934143\n",
            "0\n",
            "Batch : 174 loss = 0.27483513951301575\n",
            "1\n",
            "Batch : 175 loss = 0.21842986345291138\n",
            "0\n",
            "Batch : 176 loss = 0.5405856966972351\n",
            "0\n",
            "Batch : 177 loss = 0.4252399802207947\n",
            "1\n",
            "Batch : 178 loss = 0.3829614520072937\n",
            "1\n",
            "Batch : 179 loss = 0.36171913146972656\n",
            "1\n",
            "Batch : 180 loss = 0.19827920198440552\n",
            "0\n",
            "Batch : 181 loss = 0.3461136817932129\n",
            "1\n",
            "Batch : 182 loss = 0.2322796732187271\n",
            "0\n",
            "Batch : 183 loss = 0.10732678323984146\n",
            "0\n",
            "Batch : 184 loss = 0.2906001806259155\n",
            "1\n",
            "Batch : 185 loss = 0.3762074112892151\n",
            "1\n",
            "Batch : 186 loss = 0.2042931318283081\n",
            "0\n",
            "Batch : 187 loss = 0.41609621047973633\n",
            "1\n",
            "Batch : 188 loss = 0.28001004457473755\n",
            "1\n",
            "Batch : 189 loss = 0.4350013732910156\n",
            "0\n",
            "Batch : 190 loss = 0.5541655421257019\n",
            "0\n",
            "Batch : 191 loss = 0.308013379573822\n",
            "1\n",
            "Batch : 192 loss = 0.3866850435733795\n",
            "0\n",
            "Batch : 193 loss = 0.6380705237388611\n",
            "1\n",
            "Batch : 194 loss = 0.3469541072845459\n",
            "0\n",
            "Batch : 195 loss = 0.30821338295936584\n",
            "0\n",
            "Batch : 196 loss = 0.20037291944026947\n",
            "0\n",
            "Batch : 197 loss = 0.16537058353424072\n",
            "1\n",
            "Batch : 198 loss = 0.09540674835443497\n",
            "0\n",
            "Batch : 199 loss = 0.38925448060035706\n",
            "0\n",
            "Batch : 200 loss = 0.09762861579656601\n",
            "0\n",
            "Batch : 201 loss = 0.3410908579826355\n",
            "1\n",
            "Batch : 202 loss = 0.38002288341522217\n",
            "0\n",
            "Batch : 203 loss = 0.15223351120948792\n",
            "1\n",
            "Batch : 204 loss = 0.373437762260437\n",
            "0\n",
            "Batch : 205 loss = 0.33493271470069885\n",
            "0\n",
            "Batch : 206 loss = 0.3005320429801941\n",
            "1\n",
            "Batch : 207 loss = 0.12162390351295471\n",
            "1\n",
            "Batch : 208 loss = 0.8093025088310242\n",
            "0\n",
            "Batch : 209 loss = 0.4882446527481079\n",
            "0\n",
            "Batch : 210 loss = 0.23895353078842163\n",
            "0\n",
            "Batch : 211 loss = 0.31940609216690063\n",
            "1\n",
            "Batch : 212 loss = 0.2958880662918091\n",
            "1\n",
            "Batch : 213 loss = 0.5492139458656311\n",
            "0\n",
            "Batch : 214 loss = 0.20953279733657837\n",
            "0\n",
            "Batch : 215 loss = 0.29564613103866577\n",
            "1\n",
            "Batch : 216 loss = 0.3011975586414337\n",
            "0\n",
            "Batch : 217 loss = 0.4559608995914459\n",
            "1\n",
            "Batch : 218 loss = 0.405472069978714\n",
            "0\n",
            "Batch : 219 loss = 0.2237507551908493\n",
            "0\n",
            "Batch : 220 loss = 0.2210802137851715\n",
            "0\n",
            "Batch : 221 loss = 0.22306405007839203\n",
            "1\n",
            "Batch : 222 loss = 0.2649250030517578\n",
            "1\n",
            "Batch : 223 loss = 0.2698275148868561\n",
            "1\n",
            "Batch : 224 loss = 0.33518165349960327\n",
            "0\n",
            "Batch : 225 loss = 0.7173547744750977\n",
            "0\n",
            "Batch : 226 loss = 0.6622718572616577\n",
            "0\n",
            "Batch : 227 loss = 0.3574978709220886\n",
            "1\n",
            "Batch : 228 loss = 0.2508184015750885\n",
            "1\n",
            "Batch : 229 loss = 0.42640984058380127\n",
            "1\n",
            "Batch : 230 loss = 0.38961443305015564\n",
            "1\n",
            "Batch : 231 loss = 0.1809057742357254\n",
            "1\n",
            "Batch : 232 loss = 0.3580501079559326\n",
            "1\n",
            "Batch : 233 loss = 0.35758599638938904\n",
            "1\n",
            "Batch : 234 loss = 0.15816615521907806\n",
            "1\n",
            "Batch : 235 loss = 0.16531744599342346\n",
            "1\n",
            "Batch : 236 loss = 0.2795471251010895\n",
            "0\n",
            "Batch : 237 loss = 0.4480523467063904\n",
            "1\n",
            "Batch : 238 loss = 0.2892121970653534\n",
            "1\n",
            "Batch : 239 loss = 0.5207168459892273\n",
            "0\n",
            "Batch : 240 loss = 0.4278886914253235\n",
            "1\n",
            "Batch : 241 loss = 0.17469680309295654\n",
            "1\n",
            "Batch : 242 loss = 0.3825176954269409\n",
            "1\n",
            "Batch : 243 loss = 0.3956970274448395\n",
            "1\n",
            "Batch : 244 loss = 0.34293967485427856\n",
            "0\n",
            "Batch : 245 loss = 0.19571958482265472\n",
            "1\n",
            "Batch : 246 loss = 0.38698768615722656\n",
            "1\n",
            "Batch : 247 loss = 0.172317773103714\n",
            "0\n",
            "Batch : 248 loss = 0.5842403173446655\n",
            "0\n",
            "Batch : 249 loss = 0.3939560651779175\n",
            "0\n",
            "Batch : 250 loss = 0.09455056488513947\n",
            "1\n",
            "Batch : 251 loss = 0.3623393774032593\n",
            "0\n",
            "Batch : 252 loss = 0.16626961529254913\n",
            "1\n",
            "Batch : 253 loss = 0.11598284542560577\n",
            "0\n",
            "Batch : 254 loss = 0.6482812762260437\n",
            "1\n",
            "Batch : 255 loss = 0.17558032274246216\n",
            "0\n",
            "Batch : 256 loss = 0.11681217700242996\n",
            "1\n",
            "Batch : 257 loss = 0.31701773405075073\n",
            "0\n",
            "Batch : 258 loss = 0.1318693459033966\n",
            "1\n",
            "Batch : 259 loss = 0.18834291398525238\n",
            "1\n",
            "Batch : 260 loss = 0.3987404704093933\n",
            "1\n",
            "Batch : 261 loss = 0.30460575222969055\n",
            "0\n",
            "Batch : 262 loss = 0.08901021629571915\n",
            "1\n",
            "Batch : 263 loss = 0.3066245913505554\n",
            "0\n",
            "Batch : 0 loss = 0.10574278980493546\n",
            "1\n",
            "Batch : 1 loss = 0.29617840051651\n",
            "0\n",
            "Batch : 2 loss = 0.04121653735637665\n",
            "0\n",
            "Batch : 3 loss = 0.21977120637893677\n",
            "1\n",
            "Batch : 4 loss = 0.5343949794769287\n",
            "1\n",
            "Batch : 5 loss = 0.46569913625717163\n",
            "1\n",
            "Batch : 6 loss = 0.25189924240112305\n",
            "0\n",
            "Batch : 7 loss = 0.27913257479667664\n",
            "1\n",
            "Batch : 8 loss = 0.12812890112400055\n",
            "0\n",
            "Batch : 9 loss = 0.22588764131069183\n",
            "0\n",
            "Batch : 10 loss = 0.346795916557312\n",
            "1\n",
            "Batch : 11 loss = 0.18782606720924377\n",
            "1\n",
            "Batch : 12 loss = 0.37206703424453735\n",
            "1\n",
            "Batch : 13 loss = 0.36322563886642456\n",
            "1\n",
            "Batch : 14 loss = 0.225825697183609\n",
            "1\n",
            "Batch : 15 loss = 0.053622737526893616\n",
            "1\n",
            "Batch : 16 loss = 0.22835811972618103\n",
            "1\n",
            "Batch : 17 loss = 0.5233827829360962\n",
            "0\n",
            "Batch : 18 loss = 0.2532331347465515\n",
            "1\n",
            "Batch : 19 loss = 0.18711698055267334\n",
            "0\n",
            "Batch : 20 loss = 0.12614712119102478\n",
            "1\n",
            "Batch : 21 loss = 0.18295472860336304\n",
            "1\n",
            "Batch : 22 loss = 0.46210718154907227\n",
            "0\n",
            "Batch : 23 loss = 0.10132600367069244\n",
            "0\n",
            "Batch : 24 loss = 0.16448943316936493\n",
            "1\n",
            "Batch : 25 loss = 0.32154208421707153\n",
            "1\n",
            "Batch : 26 loss = 0.2893716096878052\n",
            "0\n",
            "Batch : 27 loss = 0.20612084865570068\n",
            "0\n",
            "Batch : 28 loss = 0.1340281218290329\n",
            "0\n",
            "Batch : 29 loss = 0.5142288208007812\n",
            "0\n",
            "Batch : 30 loss = 0.3359683156013489\n",
            "0\n",
            "Batch : 31 loss = 0.17457237839698792\n",
            "0\n",
            "Batch : 32 loss = 0.2713640332221985\n",
            "1\n",
            "Batch : 33 loss = 0.36835312843322754\n",
            "0\n",
            "Batch : 34 loss = 0.333070307970047\n",
            "1\n",
            "Batch : 35 loss = 0.15966717898845673\n",
            "0\n",
            "Batch : 36 loss = 0.05829036235809326\n",
            "1\n",
            "Batch : 37 loss = 0.20849134027957916\n",
            "0\n",
            "Batch : 38 loss = 0.4007914662361145\n",
            "1\n",
            "Batch : 39 loss = 0.038143839687108994\n",
            "1\n",
            "Batch : 40 loss = 0.23958978056907654\n",
            "0\n",
            "Batch : 41 loss = 0.039362501353025436\n",
            "1\n",
            "Batch : 42 loss = 0.08021426200866699\n",
            "0\n",
            "Batch : 43 loss = 0.2825636565685272\n",
            "0\n",
            "Batch : 44 loss = 0.5253735780715942\n",
            "1\n",
            "Batch : 45 loss = 0.142329141497612\n",
            "0\n",
            "Batch : 46 loss = 0.06931377947330475\n",
            "1\n",
            "Batch : 47 loss = 0.4203782081604004\n",
            "1\n",
            "Batch : 48 loss = 0.27068567276000977\n",
            "1\n",
            "Batch : 49 loss = 0.38251426815986633\n",
            "0\n",
            "Batch : 50 loss = 0.5504188537597656\n",
            "0\n",
            "Batch : 51 loss = 0.14651286602020264\n",
            "1\n",
            "Batch : 52 loss = 0.2745307683944702\n",
            "1\n",
            "Batch : 53 loss = 0.2599128186702728\n",
            "1\n",
            "Batch : 54 loss = 0.08775173872709274\n",
            "1\n",
            "Batch : 55 loss = 0.6508037447929382\n",
            "0\n",
            "Batch : 56 loss = 0.26473069190979004\n",
            "0\n",
            "Batch : 57 loss = 0.20658637583255768\n",
            "1\n",
            "Batch : 58 loss = 0.1250041425228119\n",
            "1\n",
            "Batch : 59 loss = 0.5068175196647644\n",
            "0\n",
            "Batch : 60 loss = 0.09991177171468735\n",
            "1\n",
            "Batch : 61 loss = 0.11808334290981293\n",
            "1\n",
            "Batch : 62 loss = 0.20343686640262604\n",
            "1\n",
            "Batch : 63 loss = 0.08457080274820328\n",
            "0\n",
            "Batch : 64 loss = 0.1565481722354889\n",
            "1\n",
            "Batch : 65 loss = 0.29440823197364807\n",
            "1\n",
            "Batch : 66 loss = 0.19211652874946594\n",
            "1\n",
            "Batch : 67 loss = 0.4044055640697479\n",
            "1\n",
            "Batch : 68 loss = 0.08530230075120926\n",
            "0\n",
            "Batch : 69 loss = 0.19680672883987427\n",
            "1\n",
            "Batch : 70 loss = 0.11294485628604889\n",
            "0\n",
            "Batch : 71 loss = 0.19341543316841125\n",
            "1\n",
            "Batch : 72 loss = 0.05033154413104057\n",
            "0\n",
            "Batch : 73 loss = 0.24242815375328064\n",
            "1\n",
            "Batch : 74 loss = 0.20964202284812927\n",
            "0\n",
            "Batch : 75 loss = 0.06194750592112541\n",
            "1\n",
            "Batch : 76 loss = 0.18972162902355194\n",
            "0\n",
            "Batch : 77 loss = 0.2534044682979584\n",
            "0\n",
            "Batch : 78 loss = 0.8607815504074097\n",
            "1\n",
            "Batch : 79 loss = 0.12363860756158829\n",
            "1\n",
            "Batch : 80 loss = 0.18242014944553375\n",
            "1\n",
            "Batch : 81 loss = 0.2502326965332031\n",
            "1\n",
            "Batch : 82 loss = 0.5202810168266296\n",
            "1\n",
            "Batch : 83 loss = 0.2507575452327728\n",
            "1\n",
            "Batch : 84 loss = 0.44479238986968994\n",
            "0\n",
            "Batch : 85 loss = 0.14381948113441467\n",
            "0\n",
            "Batch : 86 loss = 0.2134523093700409\n",
            "1\n",
            "Batch : 87 loss = 0.16106510162353516\n",
            "1\n",
            "Batch : 88 loss = 0.4194130301475525\n",
            "1\n",
            "Batch : 89 loss = 0.24264679849147797\n",
            "0\n",
            "Batch : 90 loss = 0.18948090076446533\n",
            "0\n",
            "Batch : 91 loss = 0.17357243597507477\n",
            "0\n",
            "Batch : 92 loss = 0.3764721751213074\n",
            "0\n",
            "Batch : 93 loss = 0.26549383997917175\n",
            "0\n",
            "Batch : 94 loss = 0.3074656128883362\n",
            "1\n",
            "Batch : 95 loss = 0.2047741562128067\n",
            "0\n",
            "Batch : 96 loss = 0.43011215329170227\n",
            "0\n",
            "Batch : 97 loss = 0.18502047657966614\n",
            "1\n",
            "Batch : 98 loss = 0.30203402042388916\n",
            "0\n",
            "Batch : 99 loss = 0.39268922805786133\n",
            "0\n",
            "Batch : 100 loss = 0.3057922422885895\n",
            "1\n",
            "Batch : 101 loss = 0.09762941300868988\n",
            "1\n",
            "Batch : 102 loss = 0.30890727043151855\n",
            "1\n",
            "Batch : 103 loss = 0.23808039724826813\n",
            "1\n",
            "Batch : 104 loss = 0.21219217777252197\n",
            "0\n",
            "Batch : 105 loss = 0.2584705650806427\n",
            "1\n",
            "Batch : 106 loss = 0.19848506152629852\n",
            "0\n",
            "Batch : 107 loss = 0.08645878732204437\n",
            "0\n",
            "Batch : 108 loss = 0.3749326467514038\n",
            "1\n",
            "Batch : 109 loss = 0.40045586228370667\n",
            "1\n",
            "Batch : 110 loss = 0.17665760219097137\n",
            "1\n",
            "Batch : 111 loss = 0.22141210734844208\n",
            "1\n",
            "Batch : 112 loss = 0.04436345398426056\n",
            "0\n",
            "Batch : 113 loss = 0.38572680950164795\n",
            "1\n",
            "Batch : 114 loss = 0.28953662514686584\n",
            "0\n",
            "Batch : 115 loss = 0.3512447476387024\n",
            "1\n",
            "Batch : 116 loss = 0.05393205210566521\n",
            "0\n",
            "Batch : 117 loss = 0.21693360805511475\n",
            "1\n",
            "Batch : 118 loss = 0.33793050050735474\n",
            "1\n",
            "Batch : 119 loss = 0.22792264819145203\n",
            "0\n",
            "Batch : 120 loss = 0.14151476323604584\n",
            "1\n",
            "Batch : 121 loss = 0.1914576143026352\n",
            "1\n",
            "Batch : 122 loss = 0.6629960536956787\n",
            "1\n",
            "Batch : 123 loss = 0.30929574370384216\n",
            "1\n",
            "Batch : 124 loss = 0.22648745775222778\n",
            "0\n",
            "Batch : 125 loss = 0.2366369217634201\n",
            "0\n",
            "Batch : 126 loss = 0.2465953826904297\n",
            "1\n",
            "Batch : 127 loss = 0.20192818343639374\n",
            "1\n",
            "Batch : 128 loss = 0.17255555093288422\n",
            "0\n",
            "Batch : 129 loss = 0.17483288049697876\n",
            "0\n",
            "Batch : 130 loss = 0.6807960271835327\n",
            "0\n",
            "Batch : 131 loss = 0.12154631316661835\n",
            "1\n",
            "Batch : 132 loss = 0.4492562413215637\n",
            "1\n",
            "Batch : 133 loss = 0.5408446192741394\n",
            "1\n",
            "Batch : 134 loss = 0.3509250581264496\n",
            "1\n",
            "Batch : 135 loss = 0.1885460764169693\n",
            "0\n",
            "Batch : 136 loss = 0.2726750075817108\n",
            "1\n",
            "Batch : 137 loss = 0.46380189061164856\n",
            "0\n",
            "Batch : 138 loss = 0.3545902371406555\n",
            "0\n",
            "Batch : 139 loss = 0.374623566865921\n",
            "1\n",
            "Batch : 140 loss = 0.25123900175094604\n",
            "0\n",
            "Batch : 141 loss = 0.18253828585147858\n",
            "0\n",
            "Batch : 142 loss = 0.12120479345321655\n",
            "0\n",
            "Batch : 143 loss = 0.4081357419490814\n",
            "1\n",
            "Batch : 144 loss = 0.24841712415218353\n",
            "1\n",
            "Batch : 145 loss = 0.33127695322036743\n",
            "0\n",
            "Batch : 146 loss = 0.16644386947155\n",
            "1\n",
            "Batch : 147 loss = 0.24163955450057983\n",
            "1\n",
            "Batch : 148 loss = 0.5077221393585205\n",
            "0\n",
            "Batch : 149 loss = 0.5641304850578308\n",
            "1\n",
            "Batch : 150 loss = 0.18896718323230743\n",
            "1\n",
            "Batch : 151 loss = 0.4790778160095215\n",
            "0\n",
            "Batch : 152 loss = 0.2598804831504822\n",
            "0\n",
            "Batch : 153 loss = 0.2330394834280014\n",
            "0\n",
            "Batch : 154 loss = 0.25030654668807983\n",
            "0\n",
            "Batch : 155 loss = 0.4082849621772766\n",
            "0\n",
            "Batch : 156 loss = 0.25788798928260803\n",
            "0\n",
            "Batch : 157 loss = 0.3389208912849426\n",
            "1\n",
            "Batch : 158 loss = 0.12339628487825394\n",
            "1\n",
            "Batch : 159 loss = 0.18542370200157166\n",
            "1\n",
            "Batch : 160 loss = 0.1337861567735672\n",
            "1\n",
            "Batch : 161 loss = 0.21320733428001404\n",
            "1\n",
            "Batch : 162 loss = 0.4832321107387543\n",
            "1\n",
            "Batch : 163 loss = 0.20089125633239746\n",
            "1\n",
            "Batch : 164 loss = 0.32087454199790955\n",
            "1\n",
            "Batch : 165 loss = 0.35222333669662476\n",
            "0\n",
            "Batch : 166 loss = 0.06278838962316513\n",
            "1\n",
            "Batch : 167 loss = 0.12129150331020355\n",
            "0\n",
            "Batch : 168 loss = 0.4194176495075226\n",
            "1\n",
            "Batch : 169 loss = 0.17420276999473572\n",
            "0\n",
            "Batch : 170 loss = 0.06546461582183838\n",
            "1\n",
            "Batch : 171 loss = 0.1816583275794983\n",
            "1\n",
            "Batch : 172 loss = 0.11585131287574768\n",
            "1\n",
            "Batch : 173 loss = 0.2861805558204651\n",
            "1\n",
            "Batch : 174 loss = 0.5238722562789917\n",
            "1\n",
            "Batch : 175 loss = 0.24558162689208984\n",
            "0\n",
            "Batch : 176 loss = 0.8216449022293091\n",
            "1\n",
            "Batch : 177 loss = 0.16233114898204803\n",
            "0\n",
            "Batch : 178 loss = 0.3713749647140503\n",
            "1\n",
            "Batch : 179 loss = 0.41295263171195984\n",
            "0\n",
            "Batch : 180 loss = 0.30345383286476135\n",
            "0\n",
            "Batch : 181 loss = 0.3947386145591736\n",
            "0\n",
            "Batch : 182 loss = 0.19857439398765564\n",
            "1\n",
            "Batch : 183 loss = 0.39900705218315125\n",
            "1\n",
            "Batch : 184 loss = 0.15152640640735626\n",
            "1\n",
            "Batch : 185 loss = 0.4320884644985199\n",
            "1\n",
            "Batch : 186 loss = 0.16491562128067017\n",
            "1\n",
            "Batch : 187 loss = 0.08676177263259888\n",
            "1\n",
            "Batch : 188 loss = 0.291320264339447\n",
            "1\n",
            "Batch : 189 loss = 0.07492850720882416\n",
            "0\n",
            "Batch : 190 loss = 0.3033044934272766\n",
            "1\n",
            "Batch : 191 loss = 0.6751543283462524\n",
            "1\n",
            "Batch : 192 loss = 0.2216876894235611\n",
            "1\n",
            "Batch : 193 loss = 0.07672954350709915\n",
            "1\n",
            "Batch : 194 loss = 0.483432799577713\n",
            "1\n",
            "Batch : 195 loss = 0.06610056012868881\n",
            "1\n",
            "Batch : 196 loss = 0.20117832720279694\n",
            "1\n",
            "Batch : 197 loss = 0.3472864329814911\n",
            "1\n",
            "Batch : 198 loss = 0.35618695616722107\n",
            "0\n",
            "Batch : 199 loss = 0.34487149119377136\n",
            "0\n",
            "Batch : 200 loss = 0.4353487491607666\n",
            "1\n",
            "Batch : 201 loss = 0.40490657091140747\n",
            "0\n",
            "Batch : 202 loss = 0.47860217094421387\n",
            "1\n",
            "Batch : 203 loss = 0.4695497453212738\n",
            "1\n",
            "Batch : 204 loss = 0.20191122591495514\n",
            "0\n",
            "Batch : 205 loss = 0.23734554648399353\n",
            "0\n",
            "Batch : 206 loss = 0.1780732274055481\n",
            "1\n",
            "Batch : 207 loss = 0.27840864658355713\n",
            "1\n",
            "Batch : 208 loss = 0.27128785848617554\n",
            "0\n",
            "Batch : 209 loss = 0.35231155157089233\n",
            "1\n",
            "Batch : 210 loss = 0.32568156719207764\n",
            "0\n",
            "Batch : 211 loss = 0.08677717298269272\n",
            "1\n",
            "Batch : 212 loss = 0.3653837740421295\n",
            "1\n",
            "Batch : 213 loss = 0.17336443066596985\n",
            "0\n",
            "Batch : 214 loss = 0.07757510989904404\n",
            "1\n",
            "Batch : 215 loss = 0.5101312398910522\n",
            "0\n",
            "Batch : 216 loss = 0.3015601634979248\n",
            "1\n",
            "Batch : 217 loss = 0.14420156180858612\n",
            "0\n",
            "Batch : 218 loss = 0.3063930571079254\n",
            "0\n",
            "Batch : 219 loss = 0.4360790550708771\n",
            "0\n",
            "Batch : 220 loss = 0.21769294142723083\n",
            "1\n",
            "Batch : 221 loss = 0.12187351286411285\n",
            "1\n",
            "Batch : 222 loss = 0.3981437087059021\n",
            "1\n",
            "Batch : 223 loss = 0.22904999554157257\n",
            "0\n",
            "Batch : 224 loss = 0.150549054145813\n",
            "1\n",
            "Batch : 225 loss = 0.38012924790382385\n",
            "0\n",
            "Batch : 226 loss = 0.40489697456359863\n",
            "1\n",
            "Batch : 227 loss = 0.3701227307319641\n",
            "0\n",
            "Batch : 228 loss = 0.6561695337295532\n",
            "0\n",
            "Batch : 229 loss = 0.16416078805923462\n",
            "0\n",
            "Batch : 230 loss = 0.35127609968185425\n",
            "0\n",
            "Batch : 231 loss = 0.32205629348754883\n",
            "1\n",
            "Batch : 232 loss = 0.3910124897956848\n",
            "0\n",
            "Batch : 233 loss = 0.1852223128080368\n",
            "0\n",
            "Batch : 234 loss = 0.31773602962493896\n",
            "1\n",
            "Batch : 235 loss = 0.058965519070625305\n",
            "1\n",
            "Batch : 236 loss = 0.34249642491340637\n",
            "1\n",
            "Batch : 237 loss = 0.23745256662368774\n",
            "0\n",
            "Batch : 238 loss = 0.354951411485672\n",
            "1\n",
            "Batch : 239 loss = 0.2954469919204712\n",
            "0\n",
            "Batch : 240 loss = 0.11348377168178558\n",
            "1\n",
            "Batch : 241 loss = 0.45611777901649475\n",
            "0\n",
            "Batch : 242 loss = 0.21647848188877106\n",
            "0\n",
            "Batch : 243 loss = 0.1621282398700714\n",
            "0\n",
            "Batch : 244 loss = 0.6125172972679138\n",
            "1\n",
            "Batch : 245 loss = 0.21147695183753967\n",
            "1\n",
            "Batch : 246 loss = 0.23155279457569122\n",
            "0\n",
            "Batch : 247 loss = 0.15029819309711456\n",
            "0\n",
            "Batch : 248 loss = 0.14648418128490448\n",
            "1\n",
            "Batch : 249 loss = 0.7503095269203186\n",
            "1\n",
            "Batch : 250 loss = 0.06954458355903625\n",
            "0\n",
            "Batch : 251 loss = 0.22214962542057037\n",
            "0\n",
            "Batch : 252 loss = 0.6815835237503052\n",
            "1\n",
            "Batch : 253 loss = 0.177803173661232\n",
            "0\n",
            "Batch : 254 loss = 0.19497476518154144\n",
            "1\n",
            "Batch : 255 loss = 0.31824275851249695\n",
            "1\n",
            "Batch : 256 loss = 0.31912529468536377\n",
            "0\n",
            "Batch : 257 loss = 0.3126465678215027\n",
            "0\n",
            "Batch : 258 loss = 0.09945977479219437\n",
            "1\n",
            "Batch : 259 loss = 0.4607773721218109\n",
            "0\n",
            "Batch : 260 loss = 0.1302858293056488\n",
            "0\n",
            "Batch : 261 loss = 0.14257657527923584\n",
            "1\n",
            "Batch : 262 loss = 0.2055709958076477\n",
            "1\n",
            "Batch : 263 loss = 0.3650749921798706\n",
            "1\n",
            "Batch : 0 loss = 0.2066783607006073\n",
            "1\n",
            "Batch : 1 loss = 0.19956785440444946\n",
            "0\n",
            "Batch : 2 loss = 0.19070330262184143\n",
            "1\n",
            "Batch : 3 loss = 0.13279655575752258\n",
            "1\n",
            "Batch : 4 loss = 0.2268955111503601\n",
            "1\n",
            "Batch : 5 loss = 0.29063132405281067\n",
            "1\n",
            "Batch : 6 loss = 0.2188836634159088\n",
            "1\n",
            "Batch : 7 loss = 0.13716547191143036\n",
            "0\n",
            "Batch : 8 loss = 0.15509390830993652\n",
            "0\n",
            "Batch : 9 loss = 0.41584622859954834\n",
            "0\n",
            "Batch : 10 loss = 0.12317526340484619\n",
            "0\n",
            "Batch : 11 loss = 0.20948611199855804\n",
            "0\n",
            "Batch : 12 loss = 0.4751354157924652\n",
            "0\n",
            "Batch : 13 loss = 0.06945576518774033\n",
            "0\n",
            "Batch : 14 loss = 0.10505198687314987\n",
            "0\n",
            "Batch : 15 loss = 0.24863018095493317\n",
            "0\n",
            "Batch : 16 loss = 0.11477640271186829\n",
            "1\n",
            "Batch : 17 loss = 0.1403413563966751\n",
            "1\n",
            "Batch : 18 loss = 0.30153295397758484\n",
            "0\n",
            "Batch : 19 loss = 0.32009178400039673\n",
            "0\n",
            "Batch : 20 loss = 0.4191739857196808\n",
            "1\n",
            "Batch : 21 loss = 0.1325656920671463\n",
            "0\n",
            "Batch : 22 loss = 0.2017781287431717\n",
            "1\n",
            "Batch : 23 loss = 0.3839002847671509\n",
            "1\n",
            "Batch : 24 loss = 0.05975104123353958\n",
            "1\n",
            "Batch : 25 loss = 0.1340504288673401\n",
            "1\n",
            "Batch : 26 loss = 0.1662079393863678\n",
            "0\n",
            "Batch : 27 loss = 0.2824188768863678\n",
            "1\n",
            "Batch : 28 loss = 0.18392325937747955\n",
            "1\n",
            "Batch : 29 loss = 0.16565340757369995\n",
            "1\n",
            "Batch : 30 loss = 0.18811321258544922\n",
            "1\n",
            "Batch : 31 loss = 0.22487542033195496\n",
            "0\n",
            "Batch : 32 loss = 0.11161883920431137\n",
            "0\n",
            "Batch : 33 loss = 0.11596959829330444\n",
            "1\n",
            "Batch : 34 loss = 0.09291105717420578\n",
            "1\n",
            "Batch : 35 loss = 0.09704381227493286\n",
            "1\n",
            "Batch : 36 loss = 0.017808174714446068\n",
            "1\n",
            "Batch : 37 loss = 0.4824278950691223\n",
            "1\n",
            "Batch : 38 loss = 0.21188949048519135\n",
            "0\n",
            "Batch : 39 loss = 0.2300211489200592\n",
            "0\n",
            "Batch : 40 loss = 0.14872367680072784\n",
            "0\n",
            "Batch : 41 loss = 0.2126154899597168\n",
            "1\n",
            "Batch : 42 loss = 0.22637106478214264\n",
            "0\n",
            "Batch : 43 loss = 0.33811017870903015\n",
            "1\n",
            "Batch : 44 loss = 0.2802683115005493\n",
            "1\n",
            "Batch : 45 loss = 0.20226521790027618\n",
            "0\n",
            "Batch : 46 loss = 0.10018165409564972\n",
            "0\n",
            "Batch : 47 loss = 0.038044173270463943\n",
            "1\n",
            "Batch : 48 loss = 0.043709032237529755\n",
            "0\n",
            "Batch : 49 loss = 0.17561951279640198\n",
            "0\n",
            "Batch : 50 loss = 0.0882055014371872\n",
            "0\n",
            "Batch : 51 loss = 0.07979526370763779\n",
            "0\n",
            "Batch : 52 loss = 0.17238375544548035\n",
            "1\n",
            "Batch : 53 loss = 0.06563278287649155\n",
            "1\n",
            "Batch : 54 loss = 0.12354247272014618\n",
            "1\n",
            "Batch : 55 loss = 0.1658458411693573\n",
            "1\n",
            "Batch : 56 loss = 0.19035229086875916\n",
            "0\n",
            "Batch : 57 loss = 0.213250532746315\n",
            "0\n",
            "Batch : 58 loss = 0.27498453855514526\n",
            "1\n",
            "Batch : 59 loss = 0.1777191460132599\n",
            "0\n",
            "Batch : 60 loss = 0.3201354146003723\n",
            "1\n",
            "Batch : 61 loss = 0.07136406749486923\n",
            "1\n",
            "Batch : 62 loss = 0.017837801948189735\n",
            "0\n",
            "Batch : 63 loss = 0.04504674673080444\n",
            "0\n",
            "Batch : 64 loss = 0.2890738546848297\n",
            "0\n",
            "Batch : 65 loss = 0.24116158485412598\n",
            "1\n",
            "Batch : 66 loss = 0.5481119751930237\n",
            "1\n",
            "Batch : 67 loss = 0.09785349667072296\n",
            "0\n",
            "Batch : 68 loss = 0.2644836902618408\n",
            "1\n",
            "Batch : 69 loss = 0.09940037131309509\n",
            "1\n",
            "Batch : 70 loss = 0.5888516306877136\n",
            "0\n",
            "Batch : 71 loss = 0.2793025076389313\n",
            "1\n",
            "Batch : 72 loss = 0.16373670101165771\n",
            "1\n",
            "Batch : 73 loss = 0.1675182580947876\n",
            "1\n",
            "Batch : 74 loss = 0.20242461562156677\n",
            "0\n",
            "Batch : 75 loss = 0.5150723457336426\n",
            "0\n",
            "Batch : 76 loss = 0.1917981505393982\n",
            "1\n",
            "Batch : 77 loss = 0.16676488518714905\n",
            "1\n",
            "Batch : 78 loss = 0.11446702480316162\n",
            "0\n",
            "Batch : 79 loss = 0.1191108375787735\n",
            "0\n",
            "Batch : 80 loss = 0.21602880954742432\n",
            "0\n",
            "Batch : 81 loss = 0.023381557315587997\n",
            "1\n",
            "Batch : 82 loss = 0.3153611421585083\n",
            "0\n",
            "Batch : 83 loss = 0.21389225125312805\n",
            "0\n",
            "Batch : 84 loss = 0.41131988167762756\n",
            "1\n",
            "Batch : 85 loss = 0.24485762417316437\n",
            "0\n",
            "Batch : 86 loss = 0.19128262996673584\n",
            "1\n",
            "Batch : 87 loss = 0.06474480032920837\n",
            "1\n",
            "Batch : 88 loss = 0.054146185517311096\n",
            "1\n",
            "Batch : 89 loss = 0.30032825469970703\n",
            "1\n",
            "Batch : 90 loss = 0.04637197405099869\n",
            "0\n",
            "Batch : 91 loss = 0.42178022861480713\n",
            "1\n",
            "Batch : 92 loss = 0.3252564072608948\n",
            "1\n",
            "Batch : 93 loss = 0.30532026290893555\n",
            "0\n",
            "Batch : 94 loss = 0.3187393844127655\n",
            "0\n",
            "Batch : 95 loss = 0.0574553981423378\n",
            "1\n",
            "Batch : 96 loss = 0.3316189646720886\n",
            "0\n",
            "Batch : 97 loss = 0.64759761095047\n",
            "1\n",
            "Batch : 98 loss = 0.07262634485960007\n",
            "1\n",
            "Batch : 99 loss = 0.07767441868782043\n",
            "0\n",
            "Batch : 100 loss = 0.2770729660987854\n",
            "0\n",
            "Batch : 101 loss = 0.3152141273021698\n",
            "1\n",
            "Batch : 102 loss = 0.088588647544384\n",
            "0\n",
            "Batch : 103 loss = 0.09773878008127213\n",
            "0\n",
            "Batch : 104 loss = 0.10916716605424881\n",
            "0\n",
            "Batch : 105 loss = 0.5314666628837585\n",
            "0\n",
            "Batch : 106 loss = 0.2030101716518402\n",
            "0\n",
            "Batch : 107 loss = 0.06104562059044838\n",
            "1\n",
            "Batch : 108 loss = 0.43187496066093445\n",
            "0\n",
            "Batch : 109 loss = 0.16692091524600983\n",
            "0\n",
            "Batch : 110 loss = 0.1291077882051468\n",
            "1\n",
            "Batch : 111 loss = 0.1490180641412735\n",
            "0\n",
            "Batch : 112 loss = 0.19267433881759644\n",
            "0\n",
            "Batch : 113 loss = 0.07491268962621689\n",
            "1\n",
            "Batch : 114 loss = 0.16735932230949402\n",
            "1\n",
            "Batch : 115 loss = 0.3690616190433502\n",
            "1\n",
            "Batch : 116 loss = 0.11290522664785385\n",
            "0\n",
            "Batch : 117 loss = 0.27627381682395935\n",
            "0\n",
            "Batch : 118 loss = 0.39814552664756775\n",
            "1\n",
            "Batch : 119 loss = 0.09910724312067032\n",
            "1\n",
            "Batch : 120 loss = 0.12083451449871063\n",
            "0\n",
            "Batch : 121 loss = 0.07275209575891495\n",
            "1\n",
            "Batch : 122 loss = 0.03190040588378906\n",
            "1\n",
            "Batch : 123 loss = 0.21876037120819092\n",
            "0\n",
            "Batch : 124 loss = 0.015482431277632713\n",
            "0\n",
            "Batch : 125 loss = 0.0703481137752533\n",
            "1\n",
            "Batch : 126 loss = 0.27676403522491455\n",
            "1\n",
            "Batch : 127 loss = 0.14827860891819\n",
            "1\n",
            "Batch : 128 loss = 0.16883106529712677\n",
            "0\n",
            "Batch : 129 loss = 0.16277368366718292\n",
            "1\n",
            "Batch : 130 loss = 0.09863600879907608\n",
            "0\n",
            "Batch : 131 loss = 0.20640407502651215\n",
            "1\n",
            "Batch : 132 loss = 0.01563752256333828\n",
            "1\n",
            "Batch : 133 loss = 0.013623631559312344\n",
            "1\n",
            "Batch : 134 loss = 0.17624230682849884\n",
            "1\n",
            "Batch : 135 loss = 0.3415178656578064\n",
            "1\n",
            "Batch : 136 loss = 0.15406657755374908\n",
            "1\n",
            "Batch : 137 loss = 0.1483709067106247\n",
            "0\n",
            "Batch : 138 loss = 0.48834824562072754\n",
            "1\n",
            "Batch : 139 loss = 0.10384857654571533\n",
            "1\n",
            "Batch : 140 loss = 0.08907625079154968\n",
            "0\n",
            "Batch : 141 loss = 0.27292364835739136\n",
            "1\n",
            "Batch : 142 loss = 0.4720260500907898\n",
            "0\n",
            "Batch : 143 loss = 0.09699783474206924\n",
            "1\n",
            "Batch : 144 loss = 0.25816628336906433\n",
            "0\n",
            "Batch : 145 loss = 0.07051291316747665\n",
            "0\n",
            "Batch : 146 loss = 0.7662873864173889\n",
            "0\n",
            "Batch : 147 loss = 0.07797077298164368\n",
            "1\n",
            "Batch : 148 loss = 0.2567470669746399\n",
            "1\n",
            "Batch : 149 loss = 0.2443908154964447\n",
            "1\n",
            "Batch : 150 loss = 0.2599445581436157\n",
            "1\n",
            "Batch : 151 loss = 0.2945256233215332\n",
            "1\n",
            "Batch : 152 loss = 0.5823951959609985\n",
            "0\n",
            "Batch : 153 loss = 0.10018223524093628\n",
            "1\n",
            "Batch : 154 loss = 0.15010453760623932\n",
            "1\n",
            "Batch : 155 loss = 0.21499505639076233\n",
            "1\n",
            "Batch : 156 loss = 0.10908740013837814\n",
            "1\n",
            "Batch : 157 loss = 0.4156934320926666\n",
            "1\n",
            "Batch : 158 loss = 0.33507034182548523\n",
            "1\n",
            "Batch : 159 loss = 0.3306587040424347\n",
            "1\n",
            "Batch : 160 loss = 0.38117510080337524\n",
            "0\n",
            "Batch : 161 loss = 0.21471256017684937\n",
            "0\n",
            "Batch : 162 loss = 0.22975972294807434\n",
            "1\n",
            "Batch : 163 loss = 0.16183000802993774\n",
            "1\n",
            "Batch : 164 loss = 0.10712766647338867\n",
            "1\n",
            "Batch : 165 loss = 0.25650885701179504\n",
            "0\n",
            "Batch : 166 loss = 0.2490917146205902\n",
            "1\n",
            "Batch : 167 loss = 0.1461927443742752\n",
            "1\n",
            "Batch : 168 loss = 0.27507874369621277\n",
            "1\n",
            "Batch : 169 loss = 0.29876288771629333\n",
            "1\n",
            "Batch : 170 loss = 0.23652680218219757\n",
            "1\n",
            "Batch : 171 loss = 0.10263022035360336\n",
            "0\n",
            "Batch : 172 loss = 0.055057018995285034\n",
            "1\n",
            "Batch : 173 loss = 0.26191839575767517\n",
            "1\n",
            "Batch : 174 loss = 0.19756613671779633\n",
            "0\n",
            "Batch : 175 loss = 0.08453494310379028\n",
            "1\n",
            "Batch : 176 loss = 0.15140917897224426\n",
            "0\n",
            "Batch : 177 loss = 0.4224778115749359\n",
            "0\n",
            "Batch : 178 loss = 0.188729390501976\n",
            "1\n",
            "Batch : 179 loss = 0.5442931056022644\n",
            "0\n",
            "Batch : 180 loss = 0.08525475859642029\n",
            "1\n",
            "Batch : 181 loss = 0.04314246028661728\n",
            "0\n",
            "Batch : 182 loss = 0.3012593686580658\n",
            "0\n",
            "Batch : 183 loss = 0.06666366010904312\n",
            "1\n",
            "Batch : 184 loss = 0.2860242426395416\n",
            "1\n",
            "Batch : 185 loss = 0.2278517335653305\n",
            "1\n",
            "Batch : 186 loss = 0.2096795290708542\n",
            "1\n",
            "Batch : 187 loss = 0.3261933922767639\n",
            "1\n",
            "Batch : 188 loss = 0.4717513918876648\n",
            "1\n",
            "Batch : 189 loss = 0.2615635097026825\n",
            "0\n",
            "Batch : 190 loss = 0.4262925982475281\n",
            "1\n",
            "Batch : 191 loss = 0.1241680458188057\n",
            "1\n",
            "Batch : 192 loss = 0.283095121383667\n",
            "0\n",
            "Batch : 193 loss = 0.35052087903022766\n",
            "1\n",
            "Batch : 194 loss = 0.33816277980804443\n",
            "0\n",
            "Batch : 195 loss = 0.23875553905963898\n",
            "0\n",
            "Batch : 196 loss = 0.2224440574645996\n",
            "1\n",
            "Batch : 197 loss = 0.07886558771133423\n",
            "1\n",
            "Batch : 198 loss = 0.29393553733825684\n",
            "1\n",
            "Batch : 199 loss = 0.21941861510276794\n",
            "0\n",
            "Batch : 200 loss = 0.1648944616317749\n",
            "0\n",
            "Batch : 201 loss = 0.35505804419517517\n",
            "0\n",
            "Batch : 202 loss = 0.1406371146440506\n",
            "0\n",
            "Batch : 203 loss = 0.08546242862939835\n",
            "0\n",
            "Batch : 204 loss = 0.205606609582901\n",
            "1\n",
            "Batch : 205 loss = 0.32353511452674866\n",
            "1\n",
            "Batch : 206 loss = 0.1313476711511612\n",
            "0\n",
            "Batch : 207 loss = 0.2554287612438202\n",
            "1\n",
            "Batch : 208 loss = 0.07169875502586365\n",
            "1\n",
            "Batch : 209 loss = 0.4407775104045868\n",
            "0\n",
            "Batch : 210 loss = 0.15041139721870422\n",
            "1\n",
            "Batch : 211 loss = 0.6937443017959595\n",
            "0\n",
            "Batch : 212 loss = 0.32000574469566345\n",
            "1\n",
            "Batch : 213 loss = 0.13162799179553986\n",
            "1\n",
            "Batch : 214 loss = 0.12256171554327011\n",
            "1\n",
            "Batch : 215 loss = 0.11081072688102722\n",
            "1\n",
            "Batch : 216 loss = 0.0721433013677597\n",
            "1\n",
            "Batch : 217 loss = 0.24510639905929565\n",
            "0\n",
            "Batch : 218 loss = 0.42416152358055115\n",
            "0\n",
            "Batch : 219 loss = 0.2759788930416107\n",
            "0\n",
            "Batch : 220 loss = 0.09725381433963776\n",
            "0\n",
            "Batch : 221 loss = 0.17773139476776123\n",
            "1\n",
            "Batch : 222 loss = 0.1391303688287735\n",
            "0\n",
            "Batch : 223 loss = 0.12248993664979935\n",
            "0\n",
            "Batch : 224 loss = 0.24346038699150085\n",
            "0\n",
            "Batch : 225 loss = 0.07560120522975922\n",
            "0\n",
            "Batch : 226 loss = 0.33789175748825073\n",
            "0\n",
            "Batch : 227 loss = 0.1775469183921814\n",
            "0\n",
            "Batch : 228 loss = 0.27005136013031006\n",
            "1\n",
            "Batch : 229 loss = 0.03890491649508476\n",
            "1\n",
            "Batch : 230 loss = 0.1631942242383957\n",
            "0\n",
            "Batch : 231 loss = 0.34762245416641235\n",
            "0\n",
            "Batch : 232 loss = 0.026144782081246376\n",
            "1\n",
            "Batch : 233 loss = 0.12219253927469254\n",
            "0\n",
            "Batch : 234 loss = 0.548643946647644\n",
            "0\n",
            "Batch : 235 loss = 0.5337772965431213\n",
            "1\n",
            "Batch : 236 loss = 0.12140771746635437\n",
            "0\n",
            "Batch : 237 loss = 0.1405162662267685\n",
            "1\n",
            "Batch : 238 loss = 0.2282603681087494\n",
            "0\n",
            "Batch : 239 loss = 0.2873404622077942\n",
            "0\n",
            "Batch : 240 loss = 0.15565134584903717\n",
            "1\n",
            "Batch : 241 loss = 0.24576246738433838\n",
            "0\n",
            "Batch : 242 loss = 0.1432616114616394\n",
            "1\n",
            "Batch : 243 loss = 0.0979357585310936\n",
            "1\n",
            "Batch : 244 loss = 0.2515316307544708\n",
            "1\n",
            "Batch : 245 loss = 0.15173058211803436\n",
            "1\n",
            "Batch : 246 loss = 0.05958932638168335\n",
            "1\n",
            "Batch : 247 loss = 0.30670085549354553\n",
            "1\n",
            "Batch : 248 loss = 0.3037987947463989\n",
            "1\n",
            "Batch : 249 loss = 0.17068679630756378\n",
            "1\n",
            "Batch : 250 loss = 0.33442679047584534\n",
            "1\n",
            "Batch : 251 loss = 0.19637209177017212\n",
            "1\n",
            "Batch : 252 loss = 0.1991240233182907\n",
            "1\n",
            "Batch : 253 loss = 0.4232276380062103\n",
            "0\n",
            "Batch : 254 loss = 0.20925059914588928\n",
            "0\n",
            "Batch : 255 loss = 0.3202486038208008\n",
            "0\n",
            "Batch : 256 loss = 0.2911139726638794\n",
            "0\n",
            "Batch : 257 loss = 0.05632384121417999\n",
            "0\n",
            "Batch : 258 loss = 0.3236512243747711\n",
            "1\n",
            "Batch : 259 loss = 0.24808603525161743\n",
            "1\n",
            "Batch : 260 loss = 0.13203032314777374\n",
            "0\n",
            "Batch : 261 loss = 0.19964821636676788\n",
            "1\n",
            "Batch : 262 loss = 0.18603233993053436\n",
            "1\n",
            "Batch : 263 loss = 0.03240078315138817\n"
          ]
        }
      ],
      "source": [
        "# آموزش شبکه\n",
        "loss =1\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "  if loss < 0.3:\n",
        "    break\n",
        "  model.train()\n",
        "\n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for i, batch in enumerate(dataloader):\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels = batch['label'].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "    loss = outputs.loss\n",
        "    total_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    probabilities = torch.softmax(outputs.logits, dim=1)[0]\n",
        "    predicted_label = torch.argmax(probabilities).item()\n",
        "    print(predicted_label)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted_label == labels).sum().item()\n",
        "\n",
        "    print(f'Batch : {i} loss = {loss.item()}')\n",
        "\n",
        "    # accuracy = 100 * correct / total\n",
        "\n",
        "    # print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader)}, accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "test_text = \"خیلی عالیه \"\n",
        "normalized_test_text = normalizer.normalize(test_text)\n",
        "encoding = tokenizer.encode_plus(\n",
        "    normalized_test_text,\n",
        "    add_special_tokens=True,\n",
        "    max_length=512,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "input_ids = encoding['input_ids'].to(device)\n",
        "attention_mask = encoding['attention_mask'].to(device)\n"
      ],
      "metadata": {
        "id": "NLqu7cdgQRec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    probabilities = torch.softmax(outputs.logits, dim=1)[0]\n",
        "    predicted_label = torch.argmax(probabilities).item()\n",
        "\n",
        "label_mapping = {0: 'happy', 1: 'sad'}\n",
        "predicted_class = label_mapping[predicted_label]\n",
        "print(f\"The text is about: {predicted_class}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM2OGwTWdoVB",
        "outputId": "7cb3d875-c7a3-48a0-bf36-2185ec419f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text is about: happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xRV3Rwnufal1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}